{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "import pyodbc\n",
    "from utils import get_secret\n",
    "\n",
    "class AzureSQLConnection:\n",
    "    def __init__(self, server, database, username, password, logger, driver='{ODBC Driver 18 for SQL Server}'):\n",
    "        self.conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "        self.logger = logger\n",
    "\n",
    "    def test_connection(self):\n",
    "        try:\n",
    "            conn = pyodbc.connect(self.conn_str)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('SELECT 1')\n",
    "            row = cursor.fetchone()\n",
    "            if row:\n",
    "                self.logger.info('Connection successful')\n",
    "            conn.close()\n",
    "            return True\n",
    "        except pyodbc.Error as e:\n",
    "            self.logger.error(f'Connection test failed: {str(e)}')\n",
    "            return False\n",
    "\n",
    "    def execute_query(self, query, params=None):\n",
    "        try:\n",
    "            conn = pyodbc.connect(self.conn_str)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            if params:\n",
    "                cursor.execute(query, params)\n",
    "            else:\n",
    "                cursor.execute(query)\n",
    "                \n",
    "            # For SELECT queries, return results\n",
    "            if cursor.description:\n",
    "                # Retrieve column names from the result\n",
    "                columns = [column[0] for column in cursor.description]\n",
    "                # Map each row to a dictionary using the column names\n",
    "                results = [dict(zip(columns, row)) for row in cursor.fetchall()]\n",
    "                conn.close()\n",
    "                # Convert Decimals to float if needed\n",
    "                return json.dumps(results, indent=4, default=lambda o: float(o) if isinstance(o, Decimal) else o)\n",
    "            else:\n",
    "                # For non-SELECT queries (INSERT, UPDATE, etc.)\n",
    "                conn.commit()\n",
    "                conn.close()\n",
    "                return True\n",
    "                \n",
    "        except pyodbc.Error as e:\n",
    "            if self.logger:\n",
    "                self.logger.error(f'Database error: {str(e)}')\n",
    "            raise Exception(f'Database error: {str(e)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BEN_REG  sexe  age          CIP13  total_boites      1     3    4    7  \\\n",
      "0        5     1   20  3400938014792           226  183.0   0.0  0.0  0.0   \n",
      "1        5     1   20  3400938014914           233  177.0   0.0  0.0  0.0   \n",
      "2        5     1   60  3400938014792           816  654.0  50.0  0.0  0.0   \n",
      "3        5     1   60  3400938014914           970  742.0  70.0  0.0  0.0   \n",
      "4        5     2   20  3400938014792           432  359.0  20.0  0.0  0.0   \n",
      "\n",
      "     9   14   15   35   42    90    99  \n",
      "0  0.0  0.0  0.0  0.0  0.0   0.0  43.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  26.0  30.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  56.0  56.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  93.0  65.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  25.0  28.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "DB_SERVER = get_secret('db-server')\n",
    "DB_NAME = get_secret('db-database')\n",
    "DB_USER = get_secret('db-username')\n",
    "DB_PASSWORD = get_secret('db-password')\n",
    "# 1) instantiate your connection\n",
    "conn = AzureSQLConnection(\n",
    "    server=DB_SERVER,\n",
    "    database=DB_NAME,\n",
    "    username=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    logger=None  # or your logger\n",
    ")\n",
    "\n",
    "# 2) define the two CIP13 codes\n",
    "cip_list = ['3400938014792', '3400938014914', '3400938014624']\n",
    "\n",
    "# 3) pull only those rows\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    BEN_REG,\n",
    "    sexe,\n",
    "    age,\n",
    "    CIP13,\n",
    "    PSP_SPE,\n",
    "    BOITES\n",
    "FROM dbo.MedicData\n",
    "WHERE CIP13 IN (?, ?, ?)\n",
    "\"\"\"\n",
    "# execute and parse JSON into a list of dicts\n",
    "res_json = conn.execute_query(query, cip_list)\n",
    "data = json.loads(res_json)\n",
    "\n",
    "# 4) build DataFrame and ensure BOITES is numeric\n",
    "df = pd.DataFrame(data)\n",
    "df['BOITES'] = pd.to_numeric(df['BOITES'], errors='coerce').fillna(0)\n",
    "\n",
    "# 5) total boxes per (region, sex, age, cip13)\n",
    "total = (\n",
    "    df\n",
    "    .groupby(['BEN_REG', 'sexe', 'age', 'CIP13'], as_index=False)\n",
    "    .agg(total_boites=('BOITES', 'sum'))\n",
    ")\n",
    "\n",
    "# 6) breakdown by prescriber\n",
    "dist = (\n",
    "    df\n",
    "    .groupby(['BEN_REG', 'sexe', 'age', 'CIP13', 'PSP_SPE'], as_index=False)\n",
    "    .agg(boites_by_prescriber=('BOITES', 'sum'))\n",
    ")\n",
    "\n",
    "# pivot so each prescriber becomes its own column\n",
    "dist_pivot = (\n",
    "    dist\n",
    "    .pivot_table(\n",
    "        index=['BEN_REG', 'sexe', 'age', 'CIP13'],\n",
    "        columns='PSP_SPE',\n",
    "        values='boites_by_prescriber',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 7) merge totals + distribution into one “unified_df”\n",
    "unified_df = total.merge(dist_pivot, on=['BEN_REG', 'sexe', 'age', 'CIP13'])\n",
    "\n",
    "# Now `unified_df` has:\n",
    "#   • BEN_REG, sexe, age, CIP13\n",
    "#   • total_boites\n",
    "#   • one column per PSP_SPE giving the box‐count for that prescriber\n",
    "print(unified_df.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_df.to_csv('unified_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_list = ['815', '814', '813']\n",
    "\n",
    "\n",
    "# 3) pull only those rows (note WHERE GEN_NUM IN)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    BEN_REG,\n",
    "    sexe,\n",
    "    age,\n",
    "    GEN_NUM,\n",
    "    PSP_SPE,\n",
    "    BOITES\n",
    "FROM dbo.MedicData\n",
    "WHERE GEN_NUM IN (?, ?, ?)\n",
    "\"\"\"\n",
    "res_json = conn.execute_query(query, gen_list)\n",
    "data = json.loads(res_json)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 4) coerce BOITES to numeric\n",
    "df['BOITES'] = pd.to_numeric(df['BOITES'], errors='coerce').fillna(0)\n",
    "\n",
    "# 5) total boxes per (region, sex, age, GEN_NUM)\n",
    "total = (\n",
    "    df\n",
    "    .groupby(['BEN_REG', 'sexe', 'age', 'GEN_NUM'], as_index=False)\n",
    "    .agg(total_boites=('BOITES', 'sum'))\n",
    ")\n",
    "\n",
    "# 6) breakdown by prescriber\n",
    "dist = (\n",
    "    df\n",
    "    .groupby(['BEN_REG', 'sexe', 'age', 'GEN_NUM', 'PSP_SPE'], as_index=False)\n",
    "    .agg(boites_by_prescriber=('BOITES', 'sum'))\n",
    ")\n",
    "\n",
    "# 7) pivot so each prescriber becomes its own column\n",
    "dist_pivot = (\n",
    "    dist\n",
    "    .pivot_table(\n",
    "        index=['BEN_REG', 'sexe', 'age', 'GEN_NUM'],\n",
    "        columns='PSP_SPE',\n",
    "        values='boites_by_prescriber',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 8) merge totals + distribution into one “unified_df_gen”\n",
    "unified_df_gen = total.merge(\n",
    "    dist_pivot,\n",
    "    on=['BEN_REG', 'sexe', 'age', 'GEN_NUM']\n",
    ")\n",
    "\n",
    "# 9) save or inspect\n",
    "unified_df_gen.to_csv(\"unified_df_gen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_unified(df: pd.DataFrame, product_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize brand vs generic DataFrame:\n",
    "    - Rename product code column to 'product_code'\n",
    "    - Add 'product_type' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Rename CIP13 or GEN_NUM\n",
    "    if 'CIP13' in df.columns:\n",
    "        df = df.rename(columns={'CIP13': 'product_code'})\n",
    "    elif 'GEN_NUM' in df.columns:\n",
    "        df = df.rename(columns={'GEN_NUM': 'product_code'})\n",
    "    else:\n",
    "        raise KeyError(\"No product code column found (CIP13 or GEN_NUM)\")\n",
    "    df['product_type'] = product_type\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_brand_vs_generic(brand_df: pd.DataFrame, generic_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Compare brand vs generic across segments:\n",
    "    - Region / Age / Gender segments\n",
    "    - Prescriber type breakdown\n",
    "    Returns a dict of DataFrames:\n",
    "      * 'segment_comparison'\n",
    "      * 'region_summary'\n",
    "      * 'age_summary'\n",
    "      * 'gender_summary'\n",
    "      * 'prescriber_comparison'\n",
    "    \"\"\"\n",
    "    # Prepare\n",
    "    brand = prepare_unified(brand_df, 'brand')\n",
    "    generic = prepare_unified(generic_df, 'generic')\n",
    "\n",
    "    # === Segment-level (region / sex / age) ===\n",
    "    brand_seg = brand.groupby(['BEN_REG', 'sexe', 'age'], as_index=False)       .agg(brand_total=('total_boites', 'sum'))\n",
    "    generic_seg = generic.groupby(['BEN_REG', 'sexe', 'age'], as_index=False)   .agg(generic_total=('total_boites', 'sum'))\n",
    "\n",
    "    seg = pd.merge(brand_seg, generic_seg, on=['BEN_REG', 'sexe', 'age'], how='outer').fillna(0)\n",
    "    seg['combined_total'] = seg['brand_total'] + seg['generic_total']\n",
    "    seg['brand_share'] = seg['brand_total'] / seg['combined_total']\n",
    "    seg = seg.sort_values('brand_share')\n",
    "\n",
    "    # Summaries by one dimension:\n",
    "    region_summary = seg.groupby('BEN_REG', as_index=False).agg(\n",
    "        brand_total=('brand_total', 'sum'),\n",
    "        generic_total=('generic_total', 'sum')\n",
    "    )\n",
    "    region_summary['combined_total'] = region_summary['brand_total'] + region_summary['generic_total']\n",
    "    region_summary['brand_share'] = region_summary['brand_total'] / region_summary['combined_total']\n",
    "    region_summary = region_summary.sort_values('brand_share')\n",
    "\n",
    "    age_summary = seg.groupby('age', as_index=False).agg(\n",
    "        brand_total=('brand_total', 'sum'),\n",
    "        generic_total=('generic_total', 'sum')\n",
    "    )\n",
    "    age_summary['combined_total'] = age_summary['brand_total'] + age_summary['generic_total']\n",
    "    age_summary['brand_share'] = age_summary['brand_total'] / age_summary['combined_total']\n",
    "    age_summary = age_summary.sort_values('brand_share')\n",
    "\n",
    "    gender_summary = seg.groupby('sexe', as_index=False).agg(\n",
    "        brand_total=('brand_total', 'sum'),\n",
    "        generic_total=('generic_total', 'sum')\n",
    "    )\n",
    "    gender_summary['combined_total'] = gender_summary['brand_total'] + gender_summary['generic_total']\n",
    "    gender_summary['brand_share'] = gender_summary['brand_total'] / gender_summary['combined_total']\n",
    "    gender_summary = gender_summary.sort_values('brand_share')\n",
    "\n",
    "    # === Prescriber-level breakdown ===\n",
    "    prescriber_cols_brand = [c for c in brand.columns if c not in ['BEN_REG', 'sexe', 'age', 'product_code', 'total_boites', 'product_type']]\n",
    "    prescriber_cols_gen = [c for c in generic.columns if c not in ['BEN_REG', 'sexe', 'age', 'product_code', 'total_boites', 'product_type']]\n",
    "\n",
    "    brand_presc = brand.melt(\n",
    "        id_vars=['BEN_REG', 'sexe', 'age'],\n",
    "        value_vars=prescriber_cols_brand,\n",
    "        var_name='PSP_SPE',\n",
    "        value_name='brand_boites'\n",
    "    )\n",
    "    generic_presc = generic.melt(\n",
    "        id_vars=['BEN_REG', 'sexe', 'age'],\n",
    "        value_vars=prescriber_cols_gen,\n",
    "        var_name='PSP_SPE',\n",
    "        value_name='generic_boites'\n",
    "    )\n",
    "\n",
    "    presc = pd.merge(\n",
    "        brand_presc, generic_presc,\n",
    "        on=['BEN_REG', 'sexe', 'age', 'PSP_SPE'],\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "    presc['combined_total'] = presc['brand_boites'] + presc['generic_boites']\n",
    "    presc['brand_share'] = presc['brand_boites'] / presc['combined_total']\n",
    "    presc = presc.sort_values('brand_share')\n",
    "\n",
    "    return {\n",
    "        'segment_comparison': seg,\n",
    "        'region_summary': region_summary,\n",
    "        'age_summary': age_summary,\n",
    "        'gender_summary': gender_summary,\n",
    "        'prescriber_comparison': presc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All comparison metrics have been saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "unified_df = pd.read_csv('unified_df.csv')\n",
    "unified_df_gen = pd.read_csv('unified_df_gen.csv')\n",
    "\n",
    "metrics = compare_brand_vs_generic(unified_df, unified_df_gen)\n",
    "# Save outputs\n",
    "metrics['segment_comparison'].to_csv('segment_comparison_metrics.csv', index=False)\n",
    "metrics['region_summary'].to_csv('region_summary_metrics.csv', index=False)\n",
    "metrics['age_summary'].to_csv('age_summary_metrics.csv', index=False)\n",
    "metrics['gender_summary'].to_csv('gender_summary_metrics.csv', index=False)\n",
    "metrics['prescriber_comparison'].to_csv('prescriber_comparison_metrics.csv', index=False)\n",
    "print(\"All comparison metrics have been saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SERVER = get_secret('db-server')\n",
    "DB_NAME = get_secret('db-database')\n",
    "DB_USER = get_secret('db-username')\n",
    "DB_PASSWORD = get_secret('db-password')\n",
    "# 1) instantiate your connection\n",
    "conn = AzureSQLConnection(\n",
    "    server=DB_SERVER,\n",
    "    database=DB_NAME,\n",
    "    username=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    logger=None  # or your logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assume conn is your AzureSQLConnection, and gen_list is your list of generic codes\n",
    "gen_list = ['815', '814']\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    BEN_REG,\n",
    "    sexe,\n",
    "    age,\n",
    "    GEN_NUM,\n",
    "    CIP13,\n",
    "    SUM(\n",
    "        COALESCE(\n",
    "          TRY_CAST(BOITES AS INT),\n",
    "          0\n",
    "        )\n",
    "    ) AS total_boites\n",
    "FROM dbo.MedicData\n",
    "WHERE GEN_NUM IN (?, ?)\n",
    "GROUP BY\n",
    "    BEN_REG,\n",
    "    sexe,\n",
    "    age,\n",
    "    GEN_NUM,\n",
    "    CIP13\n",
    "\"\"\"\n",
    "\n",
    "# run the query\n",
    "res_json = conn.execute_query(query, gen_list)\n",
    "df_gp = pd.DataFrame(json.loads(res_json))\n",
    "\n",
    "# coerce to numeric\n",
    "df_gp['total_boites'] = pd.to_numeric(df_gp['total_boites'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# write out for Streamlit\n",
    "df_gp.to_csv(\"generic_products_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of total_boites: 346,993\n",
      "Total sum of column '42': 732.0\n"
     ]
    }
   ],
   "source": [
    "# Read the unified_df_gen.csv file\n",
    "df = pd.read_csv(\"unified_df_gen.csv\")\n",
    "\n",
    "# Calculate total sum of total_boites\n",
    "total_boxes = df['total_boites'].sum()\n",
    "print(f\"Total sum of total_boites: {total_boxes:,}\")\n",
    "\n",
    "# Calculate total sum of column '42'\n",
    "total_42 = df['42'].sum()\n",
    "print(f\"Total sum of column '42': {total_42:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
